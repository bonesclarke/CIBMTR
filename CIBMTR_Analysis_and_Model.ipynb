{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip download lifelines\n",
    "#%pip install input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "#%pip install input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from scipy.stats import rankdata \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import catboost as cb\n",
    "\n",
    "from metric import score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set analysis output directory\n",
    "def create_output_directory(output_path):\n",
    "    \"\"\"Create the output directory if it doesn't exist and set plotting style.\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    return output_path\n",
    "\n",
    "output_path = 'working/analysis'\n",
    "create_output_directory(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "test = pd.read_csv(\"input/data/test.csv\")\n",
    "print(\"Test shape:\", test.shape )\n",
    "\n",
    "train = pd.read_csv(\"input/data/train.csv\")\n",
    "print(\"Train shape:\",train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train targets\n",
    "plt.hist(train.loc[train.efs==1,\"efs_time\"],bins=100,label=\"efs=1, Yes Event\")\n",
    "plt.hist(train.loc[train.efs==0,\"efs_time\"],bins=100,label=\"efs=0, Maybe Event\")\n",
    "plt.xlabel(\"Time of Observation, efs_time\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Times of Observation. Either time to event, or time observed without event.\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_path}times_of_observation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Two Targets into One Target with KaplanMeier\n",
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "train[\"y\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n",
    "\n",
    "plt.hist(train.loc[train.efs==1,\"y\"],bins=100,label=\"efs=1, Yes Event\")\n",
    "plt.hist(train.loc[train.efs==0,\"y\"],bins=100,label=\"efs=0, Maybe Event\")\n",
    "plt.xlabel(\"Transformed Target y\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"KaplanMeier Transformed Target y using both efs and efs_time.\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_path}kaplanmeier_transformed_target_y.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values heatmap\n",
    "def plot_missing_values_heatmap(df, output_path):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/missing_values_heatmap.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_missing_values_heatmap(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value percentages\n",
    "def plot_missing_values_bars(df, output_path):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    missing_percentages = (df.isnull().sum() / len(df) * 100).sort_values(ascending=True)\n",
    "    sns.barplot(x=missing_percentages.values, y=missing_percentages.index)\n",
    "    plt.title('Percentage of Missing Values by Column')\n",
    "    plt.xlabel('Percentage Missing')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/missing_values_percentage.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_missing_values_bars(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical distributions\n",
    "def plot_numerical_distributions(df, output_path):\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "    \n",
    "    # Create progress bar for numerical distributions\n",
    "    for col in tqdm(numerical_cols, desc=\"Creating distribution plots\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create subplot with histogram and kde\n",
    "        sns.histplot(data=df, x=col, kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # Add statistical annotations\n",
    "        stats_text = f'Mean: {df[col].mean():.2f}\\n'\n",
    "        stats_text += f'Median: {df[col].median():.2f}\\n'\n",
    "        stats_text += f'Std: {df[col].std():.2f}'\n",
    "        plt.text(0.95, 0.95, stats_text,\n",
    "                transform=plt.gca().transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/distribution_{col}.png')\n",
    "        plt.close()\n",
    "\n",
    "plot_numerical_distributions(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "def plot_correlation_matrix(df, output_path):\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "    \n",
    "    if len(numerical_cols) > 1:\n",
    "        plt.figure(figsize=(24, 16))\n",
    "        correlation_matrix = df[numerical_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/correlation_matrix.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "plot_correlation_matrix(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical distributions\n",
    "def plot_categorical_distributions(df, output_path):\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for col in tqdm(categorical_cols, desc=\"Creating categorical plots\"):\n",
    "        if df[col].nunique() < 30:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            value_counts = df[col].value_counts()\n",
    "            sns.barplot(x=value_counts.index, y=value_counts.values)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_path}/categorical_{col}.png')\n",
    "            plt.close()\n",
    "\n",
    "plot_categorical_distributions(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "print(f\"Number of Features: {len(FEATURES)} FEATURES: {FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"Missing\")\n",
    "        test[c] = test[c].fillna(\"Missing\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def feature_engineering(df):   \n",
    "    # Create age bins in 5-year intervals\n",
    "    median_age = df['age_at_hct'].median()\n",
    "    df['age_at_hct'] = df['age_at_hct'].replace([np.inf, -np.inf, '', None], np.nan).fillna(median_age)\n",
    "    df['age_bin'] = pd.cut(df['age_at_hct'], \n",
    "                          bins=range(0, 95, 5),  # From 0 to 75 in steps of 5\n",
    "                          labels=[f'{i}-{i+4}' for i in range(0, 90, 5)],\n",
    "                          include_lowest=True)\n",
    "    \n",
    "    # commorbity by age at hct\n",
    "    df['comorbidity_age'] = df['comorbidity_score'] * df['age_at_hct']\n",
    "    \n",
    "    df['age_bin_race'] = (df['age_bin'].astype(str) + '_' + \n",
    "                      df['race_group'].astype(str)).astype('category')\n",
    "\n",
    "    # age x cyto\n",
    "    df['cyto_age'] = (df['cyto_score_detail'].astype(str) + '_' + df['age_at_hct'].astype(str)).astype('category')\n",
    "\n",
    "    # Concatenate graft_type and prod_type\n",
    "    df['graft_prod'] = (df['graft_type'].astype(str) + '_' + \n",
    "                    df['prod_type'].astype(str)).astype('category')\n",
    "    \n",
    "    # Concatenate age bin and pulm severe\n",
    "    df['age_bin_pulm_severe'] = (df['age_bin'].astype(str) + '_' + \n",
    "                    df['pulm_severe'].astype(str)).astype('category')\n",
    "    \n",
    "    # Concatenate age bin, race_group, and dri score\n",
    "    df['age_bin_dri'] = (df['age_bin'].astype(str) + '_' + \n",
    "                    df['dri_score'].astype(str)).astype('category')\n",
    "\n",
    "    # hla high mean\n",
    "    df['hla_high_res_mean'] = df[['hla_high_res_8', 'hla_high_res_10', 'hla_high_res_6']].mean(axis=1)\n",
    "\n",
    "    # hla low mean\n",
    "    df['hla_low_res_mean'] = df[['hla_low_res_8', 'hla_low_res_10', 'hla_low_res_6']].mean(axis=1)\n",
    "\n",
    "    # ration of hla high and hla low\n",
    "    df['hla_ratio_res_highlow'] = (df['hla_high_res_mean']+1)/(df['hla_low_res_mean']+1)\n",
    "\n",
    "    # ration of hla low and hla high\n",
    "    df['hla_ratio_res_lowhigh'] = (df['hla_low_res_mean']+1)/(df['hla_high_res_mean']+1)\n",
    "\n",
    "    # age functions\n",
    "    df['donor_by_age_at_hct'] = (df['donor_age']/df['age_at_hct'])\n",
    "    df['comorbidity_score_by_age_at_hct'] = (df['comorbidity_score']/df['age_at_hct'])\n",
    "\n",
    "    # match drb\n",
    "    df['hla_match_drb1_mean'] = df[['hla_match_drb1_high', 'hla_match_drb1_low']].mean(axis=1)\n",
    "\n",
    "    # match dqb\n",
    "    df['hla_match_dqb1_mean'] = df[['hla_match_dqb1_high', 'hla_match_dqb1_low']].mean(axis=1)\n",
    "\n",
    "    # additional ratios\n",
    "    df['hla_high_low_ratio'] = (df['hla_high_res_mean'] + 1) / (df['hla_low_res_mean'] + 1)\n",
    "    df['drb1_dqb1_ratio'] = (df['hla_match_drb1_mean'] + 1) / (df['hla_match_dqb1_mean'] + 1)\n",
    "\n",
    "    # difference in features\n",
    "    df['high_low_diff'] = df['hla_high_res_mean'] - df['hla_low_res_mean']\n",
    "    df['drb1_dqb1_diff'] = df['hla_match_drb1_mean'] - df['hla_match_dqb1_mean']\n",
    "\n",
    "    # statistical aggregations\n",
    "    df['hla_mean'] = df[['hla_high_res_mean', 'hla_low_res_mean', 'hla_match_drb1_mean', 'hla_match_dqb1_mean']].mean(axis=1)\n",
    "    df['hla_std'] = df[['hla_high_res_mean', 'hla_low_res_mean', 'hla_match_drb1_mean', 'hla_match_dqb1_mean']].std(axis=1)\n",
    "    df['hla_max'] = df[['hla_high_res_mean', 'hla_low_res_mean', 'hla_match_drb1_mean', 'hla_match_dqb1_mean']].max(axis=1)\n",
    "    df['hla_min'] = df[['hla_high_res_mean', 'hla_low_res_mean', 'hla_match_drb1_mean', 'hla_match_dqb1_mean']].min(axis=1)\n",
    "\n",
    "    # interaction terms\n",
    "    df['drb1_high_interaction'] = df['hla_match_drb1_mean'] * df['hla_high_res_mean']\n",
    "    df['dqb1_low_interaction'] = df['hla_match_dqb1_mean'] * df['hla_low_res_mean']\n",
    "\n",
    "    # with or without TBI\n",
    "    df['with_tbi'] = np.where((df['tbi_status']).astype(str) == 'No TBI', 'no', 'yes')\n",
    "\n",
    "    # Create donor sex feature\n",
    "    df['sex_donor'] = (df['sex_match']).astype(str).str[0]\n",
    "\n",
    "    # Create recipient sex feature\n",
    "    df['sex_recipient'] = (df['sex_match']).astype(str).str[2]\n",
    "\n",
    "    # Main drug presence\n",
    "    df['has_FK'] = (df['gvhd_proph']).astype(str).str.contains('FK', na=False).astype(int)\n",
    "    df['has_MMF'] = (df['gvhd_proph']).astype(str).str.contains('MMF', na=False).astype(int)\n",
    "    df['has_MTX'] = (df['gvhd_proph']).astype(str).str.contains('MTX', na=False).astype(int)\n",
    "    df['has_CSA'] = (df['gvhd_proph']).astype(str).str.contains('CSA', na=False).astype(int)\n",
    "    df['has_cyclophosphamide'] = (df['gvhd_proph']).astype(str).str.contains('Cyclophosphamide', na=False).astype(int)\n",
    "\n",
    "    # Check for combination therapy\n",
    "    df['has_combination'] = (df['gvhd_proph']).astype(str).str.contains('\\+', na=False).astype(int)\n",
    "\n",
    "    # Count number of agents (approximate by counting '+' signs)\n",
    "    df['n_agents'] = (df['gvhd_proph']).astype(str).str.count('\\+').add(1)\n",
    "\n",
    "    # Complex vs Simple regimen\n",
    "    df['is_complex'] = (df['gvhd_proph']).astype(str).str.contains('others', na=False).astype(int)\n",
    "\n",
    "    # Depletion-based therapy\n",
    "    df['is_depletion_based'] = (df['gvhd_proph']).astype(str).str.contains('TDEPLETION|CDselect', na=False).astype(int)\n",
    "\n",
    "    # Monotherapy flag\n",
    "    df['is_monotherapy'] = (df['gvhd_proph']).astype(str).str.contains('alone', na=False).astype(int)\n",
    "\n",
    "    # No prophylaxis flag\n",
    "    df['no_prophylaxis'] = ((df['gvhd_proph']).astype(str) == 'No GvHD Prophylaxis').astype(int)\n",
    "\n",
    "    def get_primary_agent(x):\n",
    "        if pd.isna(x):\n",
    "            return 'Unknown'\n",
    "        elif 'FK' in x:\n",
    "            return 'FK-based'\n",
    "        elif 'CSA' in x:\n",
    "            return 'CSA-based'\n",
    "        elif 'Cyclophosphamide' in x:\n",
    "            return 'Cyclophosphamide-based'\n",
    "        elif 'TDEPLETION' in x or 'CDselect' in x:\n",
    "            return 'Depletion-based'\n",
    "        else:\n",
    "            return 'Other'\n",
    "\n",
    "    df['primary_agent'] = (df['gvhd_proph']).astype(str).apply(get_primary_agent)\n",
    "\n",
    "    # Standard vs Alternative approach\n",
    "    df['is_standard_approach'] = (df['gvhd_proph']).astype(str).str.contains('FK\\+ MMF|FK\\+ MTX|CSA \\+ MTX', na=False).astype(int)\n",
    "\n",
    "    # Experimental/Other\n",
    "    df['is_experimental'] = ((df['gvhd_proph']).astype(str) == 'Other GVHD Prophylaxis').astype(int)\n",
    "\n",
    "    # Combine with other relevant features\n",
    "    df['FK_MMF_interaction'] = df['has_FK'] * df['has_MMF']\n",
    "    df['CSA_MTX_interaction'] = df['has_CSA'] * df['has_MTX']\n",
    "\n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [c for c in train.columns if not c in RMV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrixn after feature engineering\n",
    "def plot_correlation_matrix(df, output_path):\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "    \n",
    "    if len(numerical_cols) > 1:\n",
    "        plt.figure(figsize=(42, 38))\n",
    "        correlation_matrix = df[numerical_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Matrix After Feature Engineering')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/correlation_matrix_feature_engineering.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "plot_correlation_matrix(train, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "for c in FEATURES:\n",
    "\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \",end=\"\")\n",
    "        combined[c],_ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "        \n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype==\"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype==\"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "    \n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CATS:\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')\n",
    "\n",
    "for col in CATS:\n",
    "    # Ensure categories are coded as integers starting from 0\n",
    "    train[col] = train[col].cat.codes\n",
    "    test[col] = test[col].cat.codes\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')\n",
    "    \n",
    "    # Verify the encoding\n",
    "    print(f\"\\nAfter fixing {col}:\")\n",
    "    print(train[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9365\n",
    "\n",
    "def perform_pca(train, test, n_components=None, random_state=42):\n",
    "    # Remove rows with NaN values from both datasets\n",
    "    train = train.dropna()\n",
    "    test = test.dropna()\n",
    "\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    train_pca = pca.fit_transform(train)\n",
    "    test_pca = pca.transform(test)\n",
    "    \n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance ratio of the components:\\n {explained_variance_ratio}\")\n",
    "    print(np.sum(explained_variance_ratio))\n",
    "    \n",
    "    train_pca_df = pd.DataFrame(train_pca, columns=[f'PC_{i+1}' for i in range(train_pca.shape[1])])\n",
    "    test_pca_df = pd.DataFrame(test_pca, columns=[f'PC_{i+1}' for i in range(test_pca.shape[1])])\n",
    "    \n",
    "    return train_pca_df, test_pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "# Extract the numerical columns to be used in the PCA\n",
    "train_num = train.drop('ID', axis=1)\n",
    "test_num = test.drop('ID', axis=1)\n",
    "\n",
    "# Get numeric and categorical columns\n",
    "numeric_columns = train.select_dtypes(include=['int32', 'float32']).columns\n",
    "categorical_columns = train.select_dtypes(exclude=['int32', 'float32']).columns\n",
    "\n",
    "# Split into numeric and categorical dataframes\n",
    "train_numeric = train_num[numeric_columns]\n",
    "test_numeric = test_num[numeric_columns]\n",
    "train_categorical = train[categorical_columns]\n",
    "test_categorical = test[categorical_columns]\n",
    "\n",
    "# Scale the numeric columns\n",
    "scaler = StandardScaler()\n",
    "train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(train_numeric),\n",
    "    columns=train_numeric.columns\n",
    ")\n",
    "test_scaled = pd.DataFrame(\n",
    "    scaler.transform(test_numeric),\n",
    "    columns=test_numeric.columns\n",
    ")\n",
    "\n",
    "train_pca, test_pca, pca = perform_pca(train_scaled, test_scaled, n_components=15, random_state=SEED)\n",
    "\n",
    "# Merge scaled numeric data with categorical data\n",
    "train_final = pd.concat([train_scaled, train_categorical, train_pca], axis=1)\n",
    "test_final = pd.concat([test_scaled, test_categorical, test_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_final\n",
    "train = train_final\n",
    "\n",
    "# add pca columns to features list\n",
    "FEATURES.extend(train_pca.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with KaplanMeier\n",
    "print(\"Using XGBoost version\",xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    #'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    #'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    #'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    #'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    #'PC_10',\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15',\n",
    "    'comorbidity_age',\n",
    "    'age_bin',\n",
    "    #'cyto_age',\n",
    "    'graft_prod',\n",
    "    'age_bin_race',\n",
    "    'age_bin_pulm_severe',\n",
    "    'hla_high_res_mean',\n",
    "    'hla_low_res_mean',\n",
    "    #'hla_ratio_res_highlow',\n",
    "    'hla_ratio_res_lowhigh',\n",
    "    'age_bin_dri',\n",
    "    'donor_by_age_at_hct',\n",
    "    'comorbidity_score_by_age_at_hct',\n",
    "    #'hla_match_drb1_mean',\n",
    "    'hla_match_dqb1_mean',\n",
    "    'hla_high_low_ratio',\n",
    "    'drb1_dqb1_ratio',\n",
    "    #'high_low_diff',\n",
    "    'drb1_dqb1_diff',\n",
    "    'hla_mean',\n",
    "    'hla_std',\n",
    "    'hla_max',\n",
    "    #'hla_min',\n",
    "    'drb1_high_interaction',\n",
    "    'dqb1_low_interaction',\n",
    "    'with_tbi',\n",
    "    'sex_donor',\n",
    "    'sex_recipient',\n",
    "    'has_FK',\n",
    "    'has_MMF',\n",
    "    'has_MTX',\n",
    "    'has_CSA',\n",
    "    #'has_cyclophosphamide',\n",
    "    'has_combination',\n",
    "    'n_agents',\n",
    "    'is_complex',\n",
    "    'is_depletion_based',\n",
    "    'is_monotherapy',\n",
    "    #'no_prophylaxis',\n",
    "    'primary_agent',\n",
    "    'is_standard_approach',\n",
    "    #'is_experimental',\n",
    "    #'FK_MMF_interaction',\n",
    "    'CSA_MTX_interaction'\n",
    "    ]\n",
    "\n",
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb = np.zeros(len(train))\n",
    "pred_xgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]\n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_xgb = XGBRegressor(\n",
    "        device=\"cuda\",\n",
    "        max_depth=6,  \n",
    "        colsample_bytree=0.5,  \n",
    "        subsample=0.8,  \n",
    "        n_estimators=2000,  \n",
    "        learning_rate=0.01,  \n",
    "        enable_categorical=True,\n",
    "        min_child_weight=80,\n",
    "        #early_stopping_rounds=25,\n",
    "    )\n",
    "    model_xgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        verbose=500 \n",
    "    )\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_xgb[test_index] = model_xgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb += model_xgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_xgb\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for XGBoost KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_xgb.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,  \n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}xgboost_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with KaplanMeier\n",
    "print(\"Using CatBoost version\",cb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    #'hla_match_c_high',\n",
    "    #'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    #'hla_low_res_6',\n",
    "    #'graft_type',\n",
    "    'vent_hist',\n",
    "    #'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    #'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    #'hla_high_res_10',\n",
    "    #'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    #'hla_match_c_low',\n",
    "    #'rituximab',\n",
    "    #'hla_match_drb1_low',\n",
    "    #'hla_match_dqb1_low',\n",
    "    #'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    #'hla_match_b_low',\n",
    "    #'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    #'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    #'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    #'PC_10',\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15',\n",
    "    'comorbidity_age',\n",
    "    'age_bin',\n",
    "    #'cyto_age',\n",
    "    'graft_prod',\n",
    "    'age_bin_race',\n",
    "    'age_bin_pulm_severe',\n",
    "    #'hla_high_res_mean',\n",
    "    'hla_low_res_mean',\n",
    "    'hla_ratio_res_highlow',\n",
    "    'hla_ratio_res_lowhigh',\n",
    "    'age_bin_dri',\n",
    "    'donor_by_age_at_hct',\n",
    "    'comorbidity_score_by_age_at_hct',\n",
    "    #'hla_match_drb1_mean',\n",
    "    #'hla_match_dqb1_mean',\n",
    "    #'hla_high_low_ratio',\n",
    "    'drb1_dqb1_ratio',\n",
    "    #'high_low_diff',\n",
    "    #'drb1_dqb1_diff',\n",
    "    'hla_mean',\n",
    "    'hla_std',\n",
    "    #'hla_max',\n",
    "    #'hla_min',\n",
    "    'drb1_high_interaction',\n",
    "    'dqb1_low_interaction',\n",
    "    'with_tbi',\n",
    "    'sex_donor',\n",
    "    #'sex_recipient',\n",
    "    'has_FK',\n",
    "    #'has_MMF',\n",
    "    #'has_MTX',\n",
    "    #'has_CSA',\n",
    "    #'has_cyclophosphamide',\n",
    "    #'has_combination',\n",
    "    #'n_agents',\n",
    "    #'is_complex',\n",
    "    #'is_depletion_based',\n",
    "    #'is_monotherapy',\n",
    "    #'no_prophylaxis',\n",
    "    'primary_agent',\n",
    "    #'is_standard_approach',\n",
    "    #'is_experimental',\n",
    "    #'FK_MMF_interaction',\n",
    "    #'CSA_MTX_interaction'\n",
    "    ]\n",
    "\n",
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_cat = np.zeros(len(train))\n",
    "pred_cat = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]\n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_cat = CatBoostRegressor(\n",
    "        task_type=\"GPU\",  \n",
    "        learning_rate=0.01,    \n",
    "        grow_policy='Lossguide',\n",
    "        depth=6,                    # Control tree depth (default=6)\n",
    "        min_data_in_leaf=1,        # Minimum number of training samples in a leaf\n",
    "        l2_leaf_reg=3.0,           # L2 regularization coefficient\n",
    "        random_strength=1,          # Random score coefficient for splitting\n",
    "        n_estimators=2000,\n",
    "        bootstrap_type='Bernoulli', # Try 'Bayesian', 'Bernoulli', 'MVS'\n",
    "        subsample=0.8,             # Sample rate for bootstrap\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    model_cat.fit(x_train,y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              cat_features=CATS,\n",
    "              verbose=250)\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_cat[test_index] = model_cat.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_cat += model_cat.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_cat /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_cat\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for CatBoost KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_cat.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES, \n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"CatBoost KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}catboost_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with KaplanMeier\n",
    "print(\"Using LightGBM version\",lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    #'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    #'hla_low_res_6',\n",
    "    #'graft_type',\n",
    "    'vent_hist',\n",
    "    #'renal_issue',\n",
    "    #'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    #'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    #'hla_high_res_10',\n",
    "    #'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    #'rituximab',\n",
    "    #'hla_match_drb1_low',\n",
    "    #'hla_match_dqb1_low',\n",
    "    #'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    #'peptic_ulcer',\n",
    "    #'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    #'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    #'hla_match_drb1_high',\n",
    "    #'pulm_moderate',\n",
    "    #'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    #'PC_10',\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15',\n",
    "    'comorbidity_age',\n",
    "    'age_bin',\n",
    "    #'cyto_age',\n",
    "    'graft_prod',\n",
    "    'age_bin_race',\n",
    "    'age_bin_pulm_severe',\n",
    "    'hla_high_res_mean',\n",
    "    'hla_low_res_mean',\n",
    "    'hla_ratio_res_highlow',\n",
    "    'hla_ratio_res_lowhigh',\n",
    "    'age_bin_dri',\n",
    "    'donor_by_age_at_hct',\n",
    "    'comorbidity_score_by_age_at_hct',\n",
    "    #'hla_match_drb1_mean',\n",
    "    #'hla_match_dqb1_mean',\n",
    "    #'hla_high_low_ratio',\n",
    "    'drb1_dqb1_ratio',\n",
    "    #'high_low_diff',\n",
    "    #'drb1_dqb1_diff',\n",
    "    'hla_mean',\n",
    "    'hla_std',\n",
    "    #'hla_max',\n",
    "    #'hla_min',\n",
    "    'drb1_high_interaction',\n",
    "    'dqb1_low_interaction',\n",
    "    #'with_tbi',\n",
    "    #'sex_donor',\n",
    "    #'sex_recipient',\n",
    "    #'has_FK',\n",
    "    #'has_MMF',\n",
    "    #'has_MTX',\n",
    "    #'has_CSA',\n",
    "    #'has_cyclophosphamide',\n",
    "    #'has_combination',\n",
    "    #'n_agents',\n",
    "    #'is_complex',\n",
    "    #'is_depletion_based',\n",
    "    #'is_monotherapy',\n",
    "    #'no_prophylaxis',\n",
    "    #'primary_agent',\n",
    "    #'is_standard_approach',\n",
    "    #'is_experimental',\n",
    "    #'FK_MMF_interaction',\n",
    "    #'CSA_MTX_interaction'\n",
    "    ]\n",
    "\n",
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_lgb = np.zeros(len(train))\n",
    "pred_lgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_lgb = LGBMRegressor(\n",
    "        device=\"gpu\",\n",
    "        num_leaves=31,\n",
    "        max_depth=3,\n",
    "        colsample_bytree=0.4,\n",
    "        subsample=0.8,\n",
    "        n_estimators=2500,\n",
    "        learning_rate=0.01,\n",
    "        objective=\"regression\",\n",
    "        verbose=-1,\n",
    "        max_bin=63,  \n",
    "        gpu_use_dp=True\n",
    "    )\n",
    "    model_lgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "    )\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_lgb += model_lgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_lgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_lgb\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for LightGBM KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_lgb.feature_importances_ \n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Importance (Gain)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"LightGBM KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}lightgbm_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with Survival:Cox\n",
    "# SURVIVAL COX NEEDS THIS TARGET (TO DIGEST EFS AND EFS_TIME)\n",
    "train[\"efs_time2\"] = train.efs_time.copy()\n",
    "train.loc[train.efs==0,\"efs_time2\"] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    #'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    #'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    #'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    #'PC_10',\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15',\n",
    "    'comorbidity_age',\n",
    "    'age_bin',\n",
    "    #'cyto_age',\n",
    "    'graft_prod',\n",
    "    'age_bin_race',\n",
    "    'age_bin_pulm_severe',\n",
    "    'hla_high_res_mean',\n",
    "    'hla_low_res_mean',\n",
    "    'hla_ratio_res_highlow',\n",
    "    'hla_ratio_res_lowhigh',\n",
    "    'age_bin_dri',\n",
    "    'donor_by_age_at_hct',\n",
    "    'comorbidity_score_by_age_at_hct',\n",
    "    'hla_match_drb1_mean',\n",
    "    'hla_match_dqb1_mean',\n",
    "    #'hla_high_low_ratio',\n",
    "    'drb1_dqb1_ratio',\n",
    "    'high_low_diff',\n",
    "    'drb1_dqb1_diff',\n",
    "    'hla_mean',\n",
    "    'hla_std',\n",
    "    'hla_max',\n",
    "    'hla_min',\n",
    "    'drb1_high_interaction',\n",
    "    'dqb1_low_interaction',\n",
    "    'with_tbi',\n",
    "    #'sex_donor',\n",
    "    #'sex_recipient',\n",
    "    'has_FK',\n",
    "    'has_MMF',\n",
    "    #'has_MTX',\n",
    "    #'has_CSA',\n",
    "    'has_cyclophosphamide',\n",
    "    #'has_combination',\n",
    "    'n_agents',\n",
    "    #'is_complex',\n",
    "    #'is_depletion_based',\n",
    "    #'is_monotherapy',\n",
    "    #'no_prophylaxis',\n",
    "    'primary_agent',\n",
    "    'is_standard_approach',\n",
    "    #'is_experimental',\n",
    "    'FK_MMF_interaction',\n",
    "    #'CSA_MTX_interaction'\n",
    "    ]\n",
    "\n",
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb_cox = np.zeros(len(train))\n",
    "pred_xgb_cox = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"efs_time2\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"efs_time2\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_xgb_cox = XGBRegressor(\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,  \n",
    "        colsample_bytree=0.5,  \n",
    "        subsample=0.8,  \n",
    "        n_estimators=2000,  \n",
    "        learning_rate=0.02,  \n",
    "        enable_categorical=True,\n",
    "        min_child_weight=80,\n",
    "        objective='survival:cox',\n",
    "        eval_metric='cox-nloglik',\n",
    "    )\n",
    "    model_xgb_cox.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        verbose=500  \n",
    "    )\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_xgb_cox[test_index] = model_xgb_cox.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb_cox += model_xgb_cox.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb_cox /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_xgb_cox\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for XGBoost Survival:Cox =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_xgb_cox.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost Survival:Cox Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}xgboost_cox_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with Survival:Cox\n",
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    #'hla_match_c_high',\n",
    "    #'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    #'hla_low_res_6',\n",
    "    #'graft_type',\n",
    "    'vent_hist',\n",
    "    #'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    #'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    #'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    #'rituximab',\n",
    "    #'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    #'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    #'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    #'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    #'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    #'PC_10',\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15',\n",
    "    'comorbidity_age',\n",
    "    'age_bin',\n",
    "    #'cyto_age',\n",
    "    'graft_prod',\n",
    "    'age_bin_race',\n",
    "    'age_bin_pulm_severe',\n",
    "    #'hla_high_res_mean',\n",
    "    'hla_low_res_mean',\n",
    "    #'hla_ratio_res_highlow',\n",
    "    'hla_ratio_res_lowhigh',\n",
    "    #'age_bin_dri',\n",
    "    'donor_by_age_at_hct',\n",
    "    'comorbidity_score_by_age_at_hct',\n",
    "    #'hla_match_drb1_mean',\n",
    "    'hla_match_dqb1_mean',\n",
    "    #'hla_high_low_ratio',\n",
    "    'drb1_dqb1_ratio',\n",
    "    #'high_low_diff',\n",
    "    #'drb1_dqb1_diff',\n",
    "    'hla_mean',\n",
    "    'hla_std',\n",
    "    #'hla_max',\n",
    "    #'hla_min',\n",
    "    #'drb1_high_interaction',\n",
    "    #'dqb1_low_interaction',\n",
    "    'with_tbi',\n",
    "    'sex_donor',\n",
    "    'sex_recipient',\n",
    "    'has_FK',\n",
    "    #'has_MMF',\n",
    "    #'has_MTX',\n",
    "    #'has_CSA',\n",
    "    #'has_cyclophosphamide',\n",
    "    #'has_combination',\n",
    "    #'n_agents',\n",
    "    #'is_complex',\n",
    "    #'is_depletion_based',\n",
    "    #'is_monotherapy',\n",
    "    #'no_prophylaxis',\n",
    "    'primary_agent',\n",
    "    #'is_standard_approach',\n",
    "    #'is_experimental',\n",
    "    #'FK_MMF_interaction',\n",
    "    #'CSA_MTX_interaction'\n",
    "    ]\n",
    "\n",
    "# Get categorical columns from train features\n",
    "CATS = train[FEATURES].select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_cat_cox = np.zeros(len(train))\n",
    "pred_cat_cox = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"efs_time2\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"efs_time2\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_cat_cox = CatBoostRegressor(\n",
    "        loss_function=\"Cox\",   \n",
    "        iterations=2000,     \n",
    "        learning_rate=0.01,  \n",
    "        grow_policy='SymmetricTree',\n",
    "        use_best_model=False,\n",
    "        early_stopping_rounds=100,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=5.0\n",
    "    )\n",
    "    model_cat_cox.fit(x_train,y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              cat_features=CATS,\n",
    "              verbose=100)\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_cat_cox[test_index] = model_cat_cox.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_cat_cox += model_cat_cox.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_cat_cox /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_cat_cox\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for CatBoost Survival:Cox =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_cat_cox.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES, \n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"CatBoost Survival:Cox Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}catboost_cox_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble CAT and XGB and LGB\n",
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = rankdata(oof_xgb) + rankdata(oof_cat) + rankdata(oof_lgb)\\\n",
    "                     + rankdata(oof_xgb_cox) + rankdata(oof_cat_cox)\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for Ensemble =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"input/data/sample_submission.csv\")\n",
    "\n",
    "# Print individual model rankings with np.set_printoptions for full output\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Combine rankings\n",
    "sub.prediction = rankdata(pred_xgb) + rankdata(pred_cat) + rankdata(pred_lgb)\\\n",
    "                    + rankdata(pred_xgb_cox) + rankdata(pred_cat_cox)\n",
    "\n",
    "print(\"\\nFinal ensemble scores:\")\n",
    "print(sub.prediction)\n",
    "\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"\\nSub shape:\", sub.shape)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
