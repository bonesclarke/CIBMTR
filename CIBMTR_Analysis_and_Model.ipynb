{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip download lifelines\n",
    "#%pip install input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "#%pip install input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "#%pip install input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from scipy.stats import rankdata \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import catboost as cb\n",
    "\n",
    "from metric import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set analysis output directory\n",
    "def create_output_directory(output_path):\n",
    "    \"\"\"Create the output directory if it doesn't exist and set plotting style.\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    return output_path\n",
    "\n",
    "output_path = 'working/analysis'\n",
    "create_output_directory(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "test = pd.read_csv(\"input/data/test.csv\")\n",
    "print(\"Test shape:\", test.shape )\n",
    "\n",
    "train = pd.read_csv(\"input/data/train.csv\")\n",
    "print(\"Train shape:\",train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train targets\n",
    "plt.hist(train.loc[train.efs==1,\"efs_time\"],bins=100,label=\"efs=1, Yes Event\")\n",
    "plt.hist(train.loc[train.efs==0,\"efs_time\"],bins=100,label=\"efs=0, Maybe Event\")\n",
    "plt.xlabel(\"Time of Observation, efs_time\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Times of Observation. Either time to event, or time observed without event.\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_path}times_of_observation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Two Targets into One Target with KaplanMeier\n",
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "train[\"y\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n",
    "\n",
    "plt.hist(train.loc[train.efs==1,\"y\"],bins=100,label=\"efs=1, Yes Event\")\n",
    "plt.hist(train.loc[train.efs==0,\"y\"],bins=100,label=\"efs=0, Maybe Event\")\n",
    "plt.xlabel(\"Transformed Target y\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"KaplanMeier Transformed Target y using both efs and efs_time.\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_path}kaplanmeier_transformed_target_y.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMV = [\"ID\",\"efs\",\"efs_time\",\"y\"]\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "print(f\"Number of Features: {len(FEATURES)} FEATURES: {FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "for c in FEATURES:\n",
    "\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \",end=\"\")\n",
    "        combined[c],_ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "        \n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype==\"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype==\"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "    \n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9365\n",
    "\n",
    "def perform_pca(train, test, n_components=None, random_state=42):\n",
    "    # Remove rows with NaN values from both datasets\n",
    "    train = train.dropna()\n",
    "    test = test.dropna()\n",
    "\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    train_pca = pca.fit_transform(train)\n",
    "    test_pca = pca.transform(test)\n",
    "    \n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance ratio of the components:\\n {explained_variance_ratio}\")\n",
    "    print(np.sum(explained_variance_ratio))\n",
    "    \n",
    "    train_pca_df = pd.DataFrame(train_pca, columns=[f'PC_{i+1}' for i in range(train_pca.shape[1])])\n",
    "    test_pca_df = pd.DataFrame(test_pca, columns=[f'PC_{i+1}' for i in range(test_pca.shape[1])])\n",
    "    \n",
    "    return train_pca_df, test_pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "# Extract the numerical columns to be used in the PCA\n",
    "train_num = train.drop('ID', axis=1)\n",
    "test_num = test.drop('ID', axis=1)\n",
    "\n",
    "# Get numeric and categorical columns\n",
    "numeric_columns = train.select_dtypes(include=['int32', 'float32']).columns\n",
    "categorical_columns = train.select_dtypes(exclude=['int32', 'float32']).columns\n",
    "\n",
    "# Split into numeric and categorical dataframes\n",
    "train_numeric = train_num[numeric_columns]\n",
    "test_numeric = test_num[numeric_columns]\n",
    "train_categorical = train[categorical_columns]\n",
    "test_categorical = test[categorical_columns]\n",
    "\n",
    "# Scale the numeric columns\n",
    "scaler = StandardScaler()\n",
    "train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(train_numeric),\n",
    "    columns=train_numeric.columns\n",
    ")\n",
    "test_scaled = pd.DataFrame(\n",
    "    scaler.transform(test_numeric),\n",
    "    columns=test_numeric.columns\n",
    ")\n",
    "\n",
    "train_pca, test_pca, pca = perform_pca(train_scaled, test_scaled, n_components=15, random_state=SEED)\n",
    "\n",
    "# Merge scaled numeric data with categorical data\n",
    "train_final = pd.concat([train_scaled, train_categorical, train_pca], axis=1)\n",
    "test_final = pd.concat([test_scaled, test_categorical, test_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_final\n",
    "train = train_final\n",
    "\n",
    "# add pca columns to features list\n",
    "FEATURES.extend(train_pca.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    'PC_1',\n",
    "    'PC_2',\n",
    "    'PC_3',\n",
    "    'PC_4',\n",
    "    'PC_5',\n",
    "    'PC_6',\n",
    "    'PC_7',\n",
    "    'PC_8',\n",
    "    'PC_9',\n",
    "    'PC_10',\n",
    "    'PC_11',\n",
    "    'PC_12',\n",
    "    'PC_13',\n",
    "    'PC_14',\n",
    "    'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "\n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with KaplanMeier\n",
    "print(\"Using XGBoost version\",xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb = np.zeros(len(train))\n",
    "pred_xgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]\n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_xgb = XGBRegressor(\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,  \n",
    "        colsample_bytree=0.5,  \n",
    "        subsample=0.8,  \n",
    "        n_estimators=2000,  \n",
    "        learning_rate=0.02,  \n",
    "        enable_categorical=True,\n",
    "        min_child_weight=80,\n",
    "        #early_stopping_rounds=25,\n",
    "    )\n",
    "    model_xgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        verbose=500 \n",
    "    )\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_xgb[test_index] = model_xgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb += model_xgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with KaplanMeier\n",
    "print(\"Using XGBoost version\",xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    #'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    #'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    #'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    #'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    #'PC_1',\n",
    "    #'PC_2',\n",
    "    #'PC_3',\n",
    "    #'PC_4',\n",
    "    #'PC_5',\n",
    "    #'PC_6',\n",
    "    #'PC_7',\n",
    "    #'PC_8',\n",
    "    #'PC_9',\n",
    "    'PC_10'\n",
    "    #'PC_11',\n",
    "    #'PC_12',\n",
    "    #'PC_13',\n",
    "    #'PC_14',\n",
    "    #'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb = np.zeros(len(train))\n",
    "pred_xgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]\n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_xgb = XGBRegressor(\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,  \n",
    "        colsample_bytree=0.5,  \n",
    "        subsample=0.8,  \n",
    "        n_estimators=2000,  \n",
    "        learning_rate=0.02,  \n",
    "        enable_categorical=True,\n",
    "        min_child_weight=80,\n",
    "        #early_stopping_rounds=25,\n",
    "    )\n",
    "    model_xgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        verbose=500 \n",
    "    )\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_xgb[test_index] = model_xgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb += model_xgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_xgb\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for XGBoost KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_xgb.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}xgboost_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with KaplanMeier\n",
    "print(\"Using CatBoost version\",cb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    #'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    #'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    #'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    #'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    #'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    #'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    #'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    'PC_1',\n",
    "    'PC_2',\n",
    "    'PC_3',\n",
    "    'PC_4',\n",
    "    'PC_5',\n",
    "    'PC_6',\n",
    "    'PC_7',\n",
    "    'PC_8',\n",
    "    'PC_9',\n",
    "    'PC_10',\n",
    "    'PC_11',\n",
    "    'PC_12',\n",
    "    'PC_13',\n",
    "    'PC_14',\n",
    "    'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_cat = np.zeros(len(train))\n",
    "pred_cat = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]\n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_cat = CatBoostRegressor(\n",
    "        task_type=\"GPU\",  \n",
    "        learning_rate=0.1,    \n",
    "        grow_policy='Lossguide',\n",
    "        #early_stopping_rounds=25,\n",
    "    )\n",
    "    model_cat.fit(x_train,y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              cat_features=CATS,\n",
    "              verbose=250)\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_cat[test_index] = model_cat.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_cat += model_cat.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_cat /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_cat\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for CatBoost KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_cat.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES, \n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"CatBoost KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}catboost_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with KaplanMeier\n",
    "print(\"Using LightGBM version\",lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    'PC_1',\n",
    "    'PC_2',\n",
    "    'PC_3',\n",
    "    'PC_4',\n",
    "    'PC_5',\n",
    "    'PC_6',\n",
    "    'PC_7',\n",
    "    'PC_8',\n",
    "    'PC_9',\n",
    "    'PC_10',\n",
    "    'PC_11',\n",
    "    'PC_12',\n",
    "    'PC_13',\n",
    "    'PC_14',\n",
    "    'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_lgb = np.zeros(len(train))\n",
    "pred_lgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"y\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_lgb = LGBMRegressor(\n",
    "        device=\"gpu\", \n",
    "        max_depth=3, \n",
    "        colsample_bytree=0.4,  \n",
    "        #subsample=0.9, \n",
    "        n_estimators=2500, \n",
    "        learning_rate=0.02, \n",
    "        objective=\"regression\", \n",
    "        verbose=-1, \n",
    "        #early_stopping_rounds=25,\n",
    "    )\n",
    "    model_lgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "    )\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_lgb += model_lgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_lgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_lgb\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for LightGBM KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_lgb.feature_importances_ \n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Importance (Gain)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"LightGBM KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}lightgbm_km_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with Survival:Cox\n",
    "# SURVIVAL COX NEEDS THIS TARGET (TO DIGEST EFS AND EFS_TIME)\n",
    "train[\"efs_time2\"] = train.efs_time.copy()\n",
    "train.loc[train.efs==0,\"efs_time2\"] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    'PC_1',\n",
    "    'PC_2',\n",
    "    'PC_3',\n",
    "    'PC_4',\n",
    "    'PC_5',\n",
    "    'PC_6',\n",
    "    'PC_7',\n",
    "    'PC_8',\n",
    "    'PC_9',\n",
    "    'PC_10',\n",
    "    'PC_11',\n",
    "    'PC_12',\n",
    "    'PC_13',\n",
    "    'PC_14',\n",
    "    'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb_cox = np.zeros(len(train))\n",
    "pred_xgb_cox = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"efs_time2\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"efs_time2\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_xgb_cox = XGBRegressor(\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,  \n",
    "        colsample_bytree=0.5,  \n",
    "        subsample=0.8,  \n",
    "        n_estimators=2000,  \n",
    "        learning_rate=0.02,  \n",
    "        enable_categorical=True,\n",
    "        min_child_weight=80,\n",
    "        objective='survival:cox',\n",
    "        eval_metric='cox-nloglik',\n",
    "    )\n",
    "    model_xgb_cox.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        verbose=500  \n",
    "    )\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_xgb_cox[test_index] = model_xgb_cox.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb_cox += model_xgb_cox.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb_cox /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_xgb_cox\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for XGBoost Survival:Cox =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_xgb_cox.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost Survival:Cox Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}xgboost_cox_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with Survival:Cox\n",
    "# feature selection\n",
    "FEATURES = ['dri_score',\n",
    "    'psych_disturb',\n",
    "    'cyto_score',\n",
    "    'diabetes',\n",
    "    'hla_match_c_high',\n",
    "    'hla_high_res_8',\n",
    "    'tbi_status',\n",
    "    'arrhythmia',\n",
    "    'hla_low_res_6',\n",
    "    'graft_type',\n",
    "    'vent_hist',\n",
    "    'renal_issue',\n",
    "    'pulm_severe',\n",
    "    'prim_disease_hct',\n",
    "    'hla_high_res_6',\n",
    "    'cmv_status',\n",
    "    'hla_high_res_10',\n",
    "    'hla_match_dqb1_high',\n",
    "    'tce_imm_match',\n",
    "    'hla_nmdp_6',\n",
    "    'hla_match_c_low',\n",
    "    'rituximab',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_dqb1_low',\n",
    "    'prod_type',\n",
    "    'cyto_score_detail',\n",
    "    'conditioning_intensity',\n",
    "    'ethnicity',\n",
    "    'year_hct',\n",
    "    'obesity',\n",
    "    'mrd_hct',\n",
    "    'in_vivo_tcd',\n",
    "    'tce_match',\n",
    "    'hla_match_a_high',\n",
    "    'hepatic_severe',\n",
    "    'donor_age',\n",
    "    'prior_tumor',\n",
    "    'hla_match_b_low',\n",
    "    'peptic_ulcer',\n",
    "    'age_at_hct',\n",
    "    'hla_match_a_low',\n",
    "    'gvhd_proph',\n",
    "    'rheum_issue',\n",
    "    'sex_match',\n",
    "    'hla_match_b_high',\n",
    "    'race_group',\n",
    "    'comorbidity_score',\n",
    "    'karnofsky_score',\n",
    "    'hepatic_mild',\n",
    "    'tce_div_match',\n",
    "    'donor_related',\n",
    "    'melphalan_dose',\n",
    "    'hla_low_res_8',\n",
    "    'cardiac',\n",
    "    'hla_match_drb1_high',\n",
    "    'pulm_moderate',\n",
    "    'hla_low_res_10',\n",
    "    'PC_1',\n",
    "    'PC_2',\n",
    "    'PC_3',\n",
    "    'PC_4',\n",
    "    'PC_5',\n",
    "    'PC_6',\n",
    "    'PC_7',\n",
    "    'PC_8',\n",
    "    'PC_9',\n",
    "    'PC_10',\n",
    "    'PC_11',\n",
    "    'PC_12',\n",
    "    'PC_13',\n",
    "    'PC_14',\n",
    "    'PC_15'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_cat_cox = np.zeros(len(train))\n",
    "pred_cat_cox = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train.loc[train_index,FEATURES].copy()\n",
    "    y_train = train.loc[train_index,\"efs_time2\"]    \n",
    "    x_valid = train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train.loc[test_index,\"efs_time2\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_cat_cox = CatBoostRegressor(\n",
    "        loss_function=\"Cox\",   \n",
    "        iterations=400,     \n",
    "        learning_rate=0.1,  \n",
    "        grow_policy='Lossguide',\n",
    "        use_best_model=False,\n",
    "    )\n",
    "    model_cat_cox.fit(x_train,y_train,\n",
    "              eval_set=(x_valid, y_valid),\n",
    "              cat_features=CATS,\n",
    "              verbose=100)\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_cat_cox[test_index] = model_cat_cox.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_cat_cox += model_cat_cox.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_cat_cox /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_cat_cox\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for CatBoost Survival:Cox =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_cat_cox.get_feature_importance()\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES, \n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"CatBoost Survival:Cox Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.savefig(f'{output_path}catboost_cox_feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble CAT and XGB and LGB\n",
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = rankdata(oof_xgb) + rankdata(oof_cat) + rankdata(oof_lgb)\\\n",
    "                     + rankdata(oof_xgb_cox) + rankdata(oof_cat_cox)\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for Ensemble =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"input/data/sample_submission.csv\")\n",
    "sub.prediction = rankdata(pred_xgb) + rankdata(pred_cat) + rankdata(pred_lgb)\\\n",
    "                     + rankdata(pred_xgb_cox) + rankdata(pred_cat_cox)\n",
    "sub.to_csv(\"submission.csv\",index=False)\n",
    "print(\"Sub shape:\",sub.shape)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
